{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"PontifexMaximus/ArabicTranslator\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"PontifexMaximus/ArabicTranslator\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of Syria?\n"
     ]
    }
   ],
   "source": [
    "print(local_llm('ماهي عاصمة سوريا؟'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation from English to Arabic Using Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install deep-translator\n",
    "! pip install googletrans==3.1.0a0\n",
    "! pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic: مرحبا، كيف حالك؟\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    translator= Translator(to_lang=\"arabic\")\n",
    "    translation = translator.translate(text)\n",
    "    return translation\n",
    "\n",
    "#english_text = \"OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as (prompts). Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.\"\n",
    "english_text = \"Hey, How are you?\"\n",
    "arabic_translation = translate_to_arabic(english_text)\n",
    "\n",
    "print(f\"Arabic: {arabic_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic: تم تدريب نماذج إنشاء النص الخاصة بـ OpenAI (التي تسمى غالبًا المحولات التوليدية المدربة مسبقًا أو نماذج اللغة الكبيرة) على فهم اللغة الطبيعية والرموز والصور. توفر النماذج مخرجات نصية استجابة لمدخلاتها. ويشار أيضًا إلى مدخلات هذه النماذج باسم (المطالبات). إن تصميم الموجه هو في الأساس كيفية \"برمجة\" نموذج نموذج لغة كبير، عادةً عن طريق تقديم تعليمات أو بعض الأمثلة حول كيفية إكمال المهمة بنجاح.\n"
     ]
    }
   ],
   "source": [
    "# https://py-googletrans.readthedocs.io/en/latest/\n",
    "from googletrans import Translator\n",
    "\n",
    "def translate_to_arabic(text):\n",
    "    translator = Translator()\n",
    "    translation = translator.translate(text, src='en', dest='ar')\n",
    "    return translation.text\n",
    "\n",
    "# english_text = \"Hey, How are you?\"\n",
    "english_text = \"OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as (prompts). Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.\"\n",
    "arabic_translation = translate_to_arabic(english_text)\n",
    "\n",
    "print(f\"Arabic: {arabic_translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'تم تدريب نماذج إنشاء النص الخاصة بـ OpenAI (التي تسمى غالبًا المحولات التوليدية المدربة مسبقًا أو نماذج اللغة الكبيرة) على فهم اللغة الطبيعية والرموز والصور. توفر النماذج مخرجات نصية استجابة لمدخلاتها. ويشار أيضًا إلى مدخلات هذه النماذج باسم (المطالبات). إن تصميم الموجه هو في الأساس كيفية \"برمجة\" نموذج نموذج لغة كبير، عادةً عن طريق تقديم تعليمات أو بعض الأمثلة حول كيفية إكمال المهمة بنجاح.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://deep-translator.readthedocs.io/en/latest/README.html\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "\n",
    "GoogleTranslator(source='en', target='ar').translate(\"keep it up, you are awesome\") \n",
    "\n",
    "english_text = \"OpenAI's text generation models (often called generative pre-trained transformers or large language models) have been trained to understand natural language, code, and images. The models provide text outputs in response to their inputs. The inputs to these models are also referred to as (prompts). Designing a prompt is essentially how you “program” a large language model model, usually by providing instructions or some examples of how to successfully complete a task.\"\n",
    "GoogleTranslator(source='en', target='ar').translate(english_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arabicthon-3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
